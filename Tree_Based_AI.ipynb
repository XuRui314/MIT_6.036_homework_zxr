{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMzP1qF/EPtlj3xvXUQl5h3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XuRui314/MIT_6.036_homework_zxr/blob/main/Tree_Based_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "这个是对应博客上决策树搭建与训练的部分，以及随机森林和GBDT的对应实现 :)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZzUiPJU_5AJN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ERrqNIPRB1J9"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = sns.load_dataset(\"iris\")\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "SHQLJPmhKUVH",
        "outputId": "4d90c339-979b-46a6-cfbf-1f36a3a12e51"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sepal_length  sepal_width  petal_length  petal_width    species\n",
              "0             5.1          3.5           1.4          0.2     setosa\n",
              "1             4.9          3.0           1.4          0.2     setosa\n",
              "2             4.7          3.2           1.3          0.2     setosa\n",
              "3             4.6          3.1           1.5          0.2     setosa\n",
              "4             5.0          3.6           1.4          0.2     setosa\n",
              "..            ...          ...           ...          ...        ...\n",
              "145           6.7          3.0           5.2          2.3  virginica\n",
              "146           6.3          2.5           5.0          1.9  virginica\n",
              "147           6.5          3.0           5.2          2.0  virginica\n",
              "148           6.2          3.4           5.4          2.3  virginica\n",
              "149           5.9          3.0           5.1          1.8  virginica\n",
              "\n",
              "[150 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b9c68d9a-a308-42c6-aaed-c89c843ebf31\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9c68d9a-a308-42c6-aaed-c89c843ebf31')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b9c68d9a-a308-42c6-aaed-c89c843ebf31 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b9c68d9a-a308-42c6-aaed-c89c843ebf31');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "决策树的组成部分其实就是决策节点、叶子节点、节点间连接关系。下面来定义节点类："
      ],
      "metadata": {
        "id": "hKFmFwVOJxMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node():\n",
        "  def __init__(self, feature_index = None, threshold = None, left = None, right = None, info_gain = None, value = None):\n",
        "    # for decision node\n",
        "    self.feature_index = feature_index\n",
        "    self.threshold = threshold\n",
        "    self.left = left\n",
        "    self.right = right\n",
        "    self.info_gain = info_gain\n",
        "\n",
        "    # for leaf node\n",
        "    self.value = value"
      ],
      "metadata": {
        "id": "aTyB8Ia4KY6u"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "然后就是decision tree的类："
      ],
      "metadata": {
        "id": "qoA5-uXvNCYv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification Tree"
      ],
      "metadata": {
        "id": "g05I1LN0qX3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTreeClassifier():\n",
        "  def __init__(self, min_samples_split = 2, max_depth = 2):\n",
        "    # initialize the root of the tree\n",
        "    self.root = None\n",
        "\n",
        "    # stopping conditions\n",
        "    self.min_samples_split = min_samples_split\n",
        "    self.max_depth = max_depth\n",
        "\n",
        "\n",
        "  def build_tree(self, dataset, curr_depth = 0):\n",
        "    ''' recursive functoin to bulid the tree'''\n",
        "    X, Y = dataset[:,:-1], dataset[:,-1]\n",
        "    num_samples, num_features = np.shape(X)\n",
        "\n",
        "    # split untill stopping conditions are met\n",
        "    if num_samples >= self.min_samples_split and curr_depth <= self.max_depth:\n",
        "      # find the best split\n",
        "      best_split = self.get_best_split(dataset, num_samples, num_features)\n",
        "      # check if information gain is positive, =0 means the data are actully just in one class\n",
        "      if best_split[\"info_gain\"] > 0:\n",
        "        # recur left\n",
        "        left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth + 1)\n",
        "        # recur right\n",
        "        right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth + 1)\n",
        "        # return decision node\n",
        "        return Node(best_split[\"feature_index\"], best_split[\"threshold\"],\n",
        "                    left_subtree, right_subtree, best_split[\"info_gain\"])\n",
        "      \n",
        "    # compute leaf node\n",
        "    leaf_value = self.calculate_leaf_value(Y)\n",
        "    # return leaf node\n",
        "    return Node(value = leaf_value)\n",
        "\n",
        "\n",
        "  def get_best_split(self, dataset, num_samples, num_features):\n",
        "    ''' function to find the best split'''\n",
        "\n",
        "    # dictionary to store the best split\n",
        "    best_split = {}\n",
        "    max_info_gain = -float(\"inf\") # initial value\n",
        "\n",
        "    # loop over all the feature \n",
        "    for feature_index in range(num_features):\n",
        "      feature_values = dataset[:,feature_index]\n",
        "      possible_thresholds = np.unique(feature_values)\n",
        "      # loop over all the feature values presnet in the data\n",
        "      for threshold in possible_thresholds:\n",
        "        # get current split\n",
        "        dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
        "        # check if childs are not null\n",
        "        if len(dataset_left)>0 and len(dataset_right)>0:\n",
        "          y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
        "          # compute information gain\n",
        "          curr_info_gain = self.information_gain(y, left_y, right_y, \"gini\")\n",
        "          # update the best split if needed\n",
        "          if curr_info_gain>max_info_gain:\n",
        "            best_split[\"feature_index\"] = feature_index\n",
        "            best_split[\"threshold\"] = threshold\n",
        "            best_split[\"dataset_left\"] = dataset_left\n",
        "            best_split[\"dataset_right\"] = dataset_right\n",
        "            best_split[\"info_gain\"] = curr_info_gain\n",
        "            max_info_gain = curr_info_gain\n",
        "            \n",
        "    # return best split\n",
        "    return best_split\n",
        "\n",
        "\n",
        "  def split(self, dataset, feature_index, threshold):\n",
        "    ''' function to find the best split '''\n",
        "    dataset_left = np.array([row for row in dataset if row[feature_index] <= threshold])\n",
        "    dataset_right = np.array([row for row in dataset if row[feature_index] > threshold])\n",
        "    return dataset_left, dataset_right\n",
        "\n",
        "\n",
        "  def information_gain(self, parent, l_child, r_child, mode=\"entropy\"):\n",
        "      ''' function to compute information gain '''\n",
        "      \n",
        "      weight_l = len(l_child) / len(parent)\n",
        "      weight_r = len(r_child) / len(parent)\n",
        "      if mode==\"gini\":\n",
        "          gain = self.gini_index(parent) - (weight_l*self.gini_index(l_child) + weight_r*self.gini_index(r_child))\n",
        "      else:\n",
        "          gain = self.entropy(parent) - (weight_l*self.entropy(l_child) + weight_r*self.entropy(r_child))\n",
        "      return gain\n",
        "  \n",
        "  def entropy(self, y):\n",
        "      ''' function to compute entropy '''\n",
        "      \n",
        "      class_labels = np.unique(y)\n",
        "      entropy = 0\n",
        "      for cls in class_labels:\n",
        "          p_cls = len(y[y == cls]) / len(y)\n",
        "          entropy += -p_cls * np.log2(p_cls)\n",
        "      return entropy\n",
        "  \n",
        "  def gini_index(self, y):\n",
        "      ''' function to compute gini index '''\n",
        "      \n",
        "      class_labels = np.unique(y)\n",
        "      gini = 0\n",
        "      for cls in class_labels:\n",
        "          p_cls = len(y[y == cls]) / len(y)\n",
        "          gini += p_cls**2\n",
        "      return 1 - gini\n",
        "      \n",
        "  def calculate_leaf_value(self, Y):\n",
        "      ''' function to compute leaf node '''\n",
        "      \n",
        "      Y = list(Y)\n",
        "      return max(Y, key=Y.count)\n",
        "  \n",
        "  def print_tree(self, tree=None, indent=\" \"):\n",
        "      ''' function to print the tree '''\n",
        "      \n",
        "      if not tree:\n",
        "          tree = self.root\n",
        "\n",
        "      if tree.value is not None:\n",
        "          print(tree.value)\n",
        "\n",
        "      else:\n",
        "          print(\"X_\"+str(tree.feature_index), \"<=\", tree.threshold, \"?\", tree.info_gain)\n",
        "          print(\"%sleft:\" % (indent), end=\"\")\n",
        "          self.print_tree(tree.left, indent + indent)\n",
        "          print(\"%sright:\" % (indent), end=\"\")\n",
        "          self.print_tree(tree.right, indent + indent)\n",
        "  \n",
        "  def fit(self, X, Y):\n",
        "      ''' function to train the tree '''\n",
        "      \n",
        "      dataset = np.concatenate((X, Y), axis=1)\n",
        "      self.root = self.build_tree(dataset)\n",
        "  \n",
        "  def predict(self, X):\n",
        "      ''' function to predict new dataset '''\n",
        "      \n",
        "      preditions = [self.make_prediction(x, self.root) for x in X]\n",
        "      return preditions\n",
        "  \n",
        "  def make_prediction(self, x, tree):\n",
        "      ''' function to predict a single data point '''\n",
        "      \n",
        "      if tree.value!=None: return tree.value\n",
        "      feature_val = x[tree.feature_index]\n",
        "      if feature_val<=tree.threshold:\n",
        "          return self.make_prediction(x, tree.left)\n",
        "      else:\n",
        "          return self.make_prediction(x, tree.right)\n",
        "\n",
        "\n",
        "      "
      ],
      "metadata": {
        "id": "CUQvswxAPP6d"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.iloc[:, :-1].values\n",
        "Y = data.iloc[:, -1].values.reshape(-1,1)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=41)"
      ],
      "metadata": {
        "id": "Ymb8ZGYEUWOt"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = DecisionTreeClassifier(min_samples_split=3, max_depth=3)\n",
        "classifier.fit(X_train,Y_train)\n",
        "classifier.print_tree()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnB0QWkZlRuv",
        "outputId": "bfe50add-8ab1-4edc-c11d-292977498b57"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_2 <= 1.9 ? 0.33741385372714494\n",
            " left:setosa\n",
            " right:X_3 <= 1.5 ? 0.427106638180289\n",
            "  left:X_2 <= 4.9 ? 0.05124653739612173\n",
            "    left:versicolor\n",
            "    right:virginica\n",
            "  right:X_2 <= 5.0 ? 0.019631171921475288\n",
            "    left:X_1 <= 2.8 ? 0.20833333333333334\n",
            "        left:virginica\n",
            "        right:versicolor\n",
            "    right:virginica\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = classifier.predict(X_test) \n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(Y_test, Y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLvcGPLilTNp",
        "outputId": "aa258331-1889-4224-94db-eb5e65e4ed7d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9333333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regression Tree"
      ],
      "metadata": {
        "id": "0WLStZgwqb1g"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n8Y4DUURqdxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "1d72tMUKmezm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "两个随机的地方，一个是数据集是Boostraping生成的，另一个是对每棵树所用特征的随机选择，这个一般取log(num_features)的数量。"
      ],
      "metadata": {
        "id": "nY_9Cd_nq_IL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import bootstrap\n",
        "import random\n",
        "from random import sample\n",
        "import math"
      ],
      "metadata": {
        "id": "XGCZFpM_xly4"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int(np.log(5) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnpOmLZG1oBQ",
        "outputId": "ec056630-4430-4edf-dcdd-6eced7af3f79"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomForestClassifier():\n",
        "  def __init__(self, n_estimators = 100, min_samples_split = 2, max_depth = 2, random_state = 0):\n",
        "    # initialize the forest\n",
        "    self.forest = [] # the list of all the roots of trees in the forest\n",
        "\n",
        "    # other parameters\n",
        "    self.min_samples_split = min_samples_split\n",
        "    self.max_depth = max_depth\n",
        "    self.n_estimators = n_estimators\n",
        "    self.random_state = random_state\n",
        "\n",
        "  def build_forest(self, dataset, curr_depth = 0):\n",
        "    \n",
        "    num_samples, num_features = np.shape(X)\n",
        "    feature_indexs = np.arange(num_features).tolist()\n",
        "    num_select_features = int(np.log(num_features))\n",
        "\n",
        "    for i in range(n_estimators):\n",
        "      ''' Bootstrap sampling the dataset '''\n",
        "      data_sampled = np.random.choice(dataset, size=len(dataset))\n",
        "      feature_indexs = sample(feature_indexs, num_select_features)\n",
        "\n",
        "      X, Y = dataset[:,:-1], dataset[:,-1]\n",
        "      X_sampled = \n",
        "      Y_sampled = \n",
        "      ''' Random select the features '''\n",
        "      X_data = \n",
        "      Y_data = \n",
        "\n",
        "      single_tree = DecisionTreeClassifier(min_samples_split=min_samples_split, max_depth=max_depth)\n",
        "      single_tree.fit(X_data, Y_data)\n",
        "      self.forest.append(single_tree) \n",
        "\n",
        "\n",
        "\n",
        "  def fit(self, X, Y):\n",
        "      ''' function to train the tree '''\n",
        "      \n",
        "      dataset = np.concatenate((X, Y), axis=1)\n",
        "      self.forest = self.build_forest(dataset)\n",
        "  \n",
        "  def predict(self, X):\n",
        "      ''' function to predict new dataset '''\n",
        "      preditions_all = [] # matrix (n_estimators, X.size)\n",
        "      for i in range(n_estimators):\n",
        "        preditions.append(self.forest[i].predict(X))\n",
        "      \n",
        "      predictions = []\n",
        "\n",
        "      return preditions "
      ],
      "metadata": {
        "id": "DA3K_NYQqJRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = RandomForestClassifier(min_samples_split=3, max_depth=3)\n",
        "classifier.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "76qvVRiAmeOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = classifier.predict(X_test) \n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(Y_test, Y_pred)"
      ],
      "metadata": {
        "id": "HGxK73DstdI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IC_3h8bmvYPl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}